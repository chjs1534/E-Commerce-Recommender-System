{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install polars","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:21:53.501645Z","iopub.execute_input":"2023-08-02T06:21:53.503967Z","iopub.status.idle":"2023-08-02T06:22:07.705438Z","shell.execute_reply.started":"2023-08-02T06:21:53.503907Z","shell.execute_reply":"2023-08-02T06:22:07.704068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import polars as pl\n\ntrain = pl.read_parquet('../input/otto-train-and-test-data-for-local-validation/train.parquet')\nvalidA = pl.read_parquet('../input/otto-train-and-test-data-for-local-validation/test.parquet')\nvalidB = pl.read_parquet('../input/otto-train-and-test-data-for-local-validation/test_labels.parquet')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-02T11:15:38.770850Z","iopub.execute_input":"2023-08-02T11:15:38.771316Z","iopub.status.idle":"2023-08-02T11:15:53.314541Z","shell.execute_reply.started":"2023-08-02T11:15:38.771283Z","shell.execute_reply":"2023-08-02T11:15:53.313612Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"id2type = ['clicks', 'carts', 'orders']\ntype2id = {'clicks': 0, 'carts': 1, 'orders': 2}","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:22:15.561587Z","iopub.execute_input":"2023-08-02T06:22:15.562358Z","iopub.status.idle":"2023-08-02T06:22:15.567279Z","shell.execute_reply.started":"2023-08-02T06:22:15.562323Z","shell.execute_reply":"2023-08-02T06:22:15.566337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Get subset of data \nfraction_of_sessions = 0.2\n\ntrain_sessions = train['session'].sample(fraction=fraction_of_sessions, seed=42)\ntrain = train.filter(pl.col(\"session\").is_in(train_sessions))\ntrain = train.sort(\"session\")\n\nvalidation_sessions = validA['session'].sample(fraction=fraction_of_sessions, seed=42)\nvalidA = validA.filter(pl.col(\"session\").is_in(validation_sessions))\nvalidA = validA.sort(\"session\")\n\nvalidB = validB.filter(pl.col(\"session\").is_in(validation_sessions))\nvalidB = validB.sort(\"session\")\n\nprint(train.shape[0], validA.shape[0], validB.shape[0])\n\nprint(train, validA, validB)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:15:53.316001Z","iopub.execute_input":"2023-08-02T11:15:53.316321Z","iopub.status.idle":"2023-08-02T11:16:12.217811Z","shell.execute_reply.started":"2023-08-02T11:15:53.316292Z","shell.execute_reply":"2023-08-02T11:16:12.216975Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"152268691 5763556 1007030\nshape: (152_268_691, 4)\n┌──────────┬─────────┬────────────┬──────┐\n│ session  ┆ aid     ┆ ts         ┆ type │\n│ ---      ┆ ---     ┆ ---        ┆ ---  │\n│ i32      ┆ i32     ┆ i32        ┆ u8   │\n╞══════════╪═════════╪════════════╪══════╡\n│ 0        ┆ 1517085 ┆ 1659304800 ┆ 0    │\n│ 0        ┆ 1563459 ┆ 1659304904 ┆ 0    │\n│ 0        ┆ 1309446 ┆ 1659367439 ┆ 0    │\n│ 0        ┆ 16246   ┆ 1659367719 ┆ 0    │\n│ …        ┆ …       ┆ …          ┆ …    │\n│ 11098496 ┆ 219035  ┆ 1661119183 ┆ 0    │\n│ 11098507 ┆ 1195266 ┆ 1661119189 ┆ 0    │\n│ 11098512 ┆ 8664    ┆ 1661119192 ┆ 0    │\n│ 11098522 ┆ 1524949 ┆ 1661119197 ┆ 0    │\n└──────────┴─────────┴────────────┴──────┘ shape: (5_763_556, 4)\n┌──────────┬─────────┬────────────┬──────┐\n│ session  ┆ aid     ┆ ts         ┆ type │\n│ ---      ┆ ---     ┆ ---        ┆ ---  │\n│ i32      ┆ i32     ┆ i32        ┆ u8   │\n╞══════════╪═════════╪════════════╪══════╡\n│ 11098529 ┆ 1105029 ┆ 1661119200 ┆ 0    │\n│ 11098531 ┆ 452188  ┆ 1661119200 ┆ 0    │\n│ 11098531 ┆ 1239060 ┆ 1661119227 ┆ 0    │\n│ 11098531 ┆ 1557766 ┆ 1661119243 ┆ 0    │\n│ …        ┆ …       ┆ …          ┆ …    │\n│ 12899763 ┆ 1539032 ┆ 1661723978 ┆ 0    │\n│ 12899769 ┆ 719585  ┆ 1661723962 ┆ 0    │\n│ 12899771 ┆ 1160655 ┆ 1661723965 ┆ 0    │\n│ 12899775 ┆ 1743151 ┆ 1661723970 ┆ 0    │\n└──────────┴─────────┴────────────┴──────┘ shape: (1_007_030, 3)\n┌──────────┬────────┬─────────────────────────────┐\n│ session  ┆ type   ┆ ground_truth                │\n│ ---      ┆ ---    ┆ ---                         │\n│ i64      ┆ str    ┆ list[i64]                   │\n╞══════════╪════════╪═════════════════════════════╡\n│ 11098529 ┆ clicks ┆ [1105029]                   │\n│ 11098531 ┆ orders ┆ [1365569]                   │\n│ 11098533 ┆ clicks ┆ [1417450]                   │\n│ 11098533 ┆ carts  ┆ [108676, 1406660, … 777657] │\n│ …        ┆ …      ┆ …                           │\n│ 12899763 ┆ clicks ┆ [750901]                    │\n│ 12899769 ┆ clicks ┆ [1393784]                   │\n│ 12899771 ┆ clicks ┆ [215084]                    │\n│ 12899775 ┆ clicks ┆ [1760714]                   │\n└──────────┴────────┴─────────────────────────────┘\n","output_type":"stream"}]},{"cell_type":"code","source":"# Simple candidate generator \ndef generate_candidates_simple(df, dict_format=False):\n    df = df.groupby(['session', 'aid']).agg(pl.count())\n    df = df.sort('session', 'count', descending=[False, True]).groupby('session').head(50)\n    if dict_format:\n        df = df.groupby('session').agg(pl.col(\"aid\"))\n        result = {}\n        for session, aid_list in zip(df['session'].to_list(), df['aid'].to_list()):\n            result[session] = aid_list \n        return result\n    \n    return df.select('session', 'aid').sort(['session', 'aid'])","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:22:34.595017Z","iopub.execute_input":"2023-08-02T06:22:34.595372Z","iopub.status.idle":"2023-08-02T06:22:34.604189Z","shell.execute_reply.started":"2023-08-02T06:22:34.595343Z","shell.execute_reply":"2023-08-02T06:22:34.602952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type_weight = {0: 1, 1: 6, 2: 3}\n\n# Memory Issues when merging\ndef generate_covisit(df, event_type):\n    if event_type == 0:\n        df = train\n        df = df.sort(['session', 'ts'], descending=[False, True])\n        # get most recent events for each session\n        df = df.groupby('session').tail(30)\n        # find pairs of items that were accessed within a day of each other\n        df = df.join(df, on='session', suffix=\"_next\")\n        df = df.filter((pl.col(\"aid\") != pl.col(\"aid_next\")) & \n                       (pl.col(\"type\") != pl.col(\"type_next\")) &\n                       (pl.col(\"ts\") != pl.col(\"ts_next\")))\n        df = df.with_columns(((pl.col(\"ts_next\") - pl.col(\"ts\")) / (24 * 60 * 60 * 1000)).alias(\"days_elapsed\"))\n        df = df.filter((pl.col(\"days_elapsed\") >= 0) & (pl.col(\"days_elapsed\") <= 1))\n        df = df.with_columns(pl.col(\"type\").map_dict(type_weight).alias(\"weight\"))\n        df = df.groupby(['aid', 'aid_next']).agg(pl.sum(\"weight\"))\n        df = df.sort(['aid', 'aid_next', 'weight'], descending=[False, False, True]).groupby('aid').head(40).select(['aid', 'aid_next'])\n        df = df.groupby('aid').agg(pl.col(\"aid_next\"))\n        \n        covisit = {}\n        for aid, aid_list in zip(df[\"aid\"], df[\"aid_next\"]):\n            covisit[aid] = aid_list\n            \n        return covisit\n    if event_type == 1:\n        return \n    if event_type == 2:\n        return \n\ndef generate_candidate(df, event_type):\n    if event_type == 0:\n        aids = df[\"aid\"].to_list()\n        types = df[\"type\"].to_list()\n        unique_aids = dict(list(aids[::-1]))\n        \n        if len(unique_aids) >= 20:\n            weights=np.logspace(0.1,1,len(aids),base=2, endpoint=True)-1\n            aids_temp=defaultdict(lambda: 0)\n            for aid,w,t in zip(AIDs,weights,types): \n                aids_temp[aid]+= w * type_weight_multipliers[t]\n\n            sorted_aids=[k for k, v in sorted(aids_temp.items(), key=lambda item: -item[1])]\n            labels.append(sorted_aids[:20])\n\n    else:\n        return\n    \n    generate_covisit(df, 0)\n    \n# def most_common_values(df):\n#     def most_common_values_(l):\n#         values, count = zip(*Counter(l).most_common(50))\n#         return values\n    \n#     top_clicks = most_common_values_(df.filter(pl.col(\"type\") == 0)).to_list()\n#     top_add2carts = most_common_values_(df.filter(pl.col(\"type\") == 1)).to_list()\n#     top_buys = most_common_values_(df.filter(pl.col(\"type\") == 2)).to_list()\n    \n#     return (top_clicks, top_add2carts, top_buys)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:22:34.605758Z","iopub.execute_input":"2023-08-02T06:22:34.606253Z","iopub.status.idle":"2023-08-02T06:22:34.628493Z","shell.execute_reply.started":"2023-08-02T06:22:34.606218Z","shell.execute_reply":"2023-08-02T06:22:34.627094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\ntype_weight = {0: 1, 1: 6, 2: 3}\ndef generate_candidates(df, event_type, covisit):\n    if event_type == 0:\n        aids = df[\"aid\"].to_list()\n        types = df[\"type\"].to_list()\n        unique_aids = list(dict.fromkeys(aids[::-1]))\n        \n        time_weights = np.logspace(0.1,1,len(aids),base=2, endpoint=True)-1\n        aids_counter = {}\n        for aid, w, t in zip(aids, time_weights, types):\n            aids_counter[aid] = aids_counter.get(aid, 0) + w * type_weight[t]\n            \n        aids_counter_sorted = sorted(aids_counter.items(), key=lambda x: x[1])\n        candidates = [k for k, v in aids_counter_sorted]\n        \n        if len(candidates) <= 20:\n            secondary_candidates_counter = Counter()\n            for candidate in candidates:\n                secondary_candidates_counter.update(covisit.get(aid, []))  \n            secondary_candidates = [k for k, v in secondary_candidates_counter.most_common(40)]\n            return candidates[:40] + secondary_candidates[:(40 - len(candidates))]\n\n        return candidates[:40]\n    return","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:20:38.376790Z","iopub.execute_input":"2023-08-02T11:20:38.377342Z","iopub.status.idle":"2023-08-02T11:20:38.390635Z","shell.execute_reply.started":"2023-08-02T11:20:38.377304Z","shell.execute_reply":"2023-08-02T11:20:38.388914Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\nDISK_PIECES = 4\n\n# Improved speed for 2X using polars. \ndef pqt_to_dict(path):\n    return pl.read_parquet(path).groupby('aid_x').agg(pl.col('aid_y')).to_pandas().set_index('aid_x').aid_y.apply(list).to_dict()\n\n# LOAD THREE CO-VISITATION MATRICES\ncovisit = pqt_to_dict(f'/kaggle/input/otto-covisitation-matrix-parquet-files/top_20_clicks_v7_0.pqt')\n\nfor k in range(1,DISK_PIECES): \n    covisit.update(pd.read_parquet(f'/kaggle/input/otto-covisitation-matrix-parquet-files/top_20_clicks_v7_{k}.pqt') ) ","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:16:12.237834Z","iopub.execute_input":"2023-08-02T11:16:12.238556Z","iopub.status.idle":"2023-08-02T11:16:22.223668Z","shell.execute_reply.started":"2023-08-02T11:16:12.238511Z","shell.execute_reply":"2023-08-02T11:16:22.222684Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:29:40.984460Z","iopub.execute_input":"2023-08-02T11:29:40.984967Z","iopub.status.idle":"2023-08-02T11:32:24.011552Z","shell.execute_reply.started":"2023-08-02T11:29:40.984928Z","shell.execute_reply":"2023-08-02T11:32:24.010100Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:40:39.912790Z","iopub.execute_input":"2023-08-02T11:40:39.913270Z","iopub.status.idle":"2023-08-02T11:40:40.068129Z","shell.execute_reply.started":"2023-08-02T11:40:39.913234Z","shell.execute_reply":"2023-08-02T11:40:40.066834Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"shape: (6_503_686, 2)\n┌──────────┬─────────┐\n│ session  ┆ aid     │\n│ ---      ┆ ---     │\n│ i64      ┆ i64     │\n╞══════════╪═════════╡\n│ 11098529 ┆ 1105029 │\n│ 11098531 ┆ 624163  │\n│ 11098531 ┆ 1553691 │\n│ 11098531 ┆ 1449555 │\n│ …        ┆ …       │\n│ 12899763 ┆ 750901  │\n│ 12899769 ┆ 719585  │\n│ 12899771 ┆ 1160655 │\n│ 12899775 ┆ 1743151 │\n└──────────┴─────────┘","text/html":"<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (6_503_686, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>session</th><th>aid</th></tr><tr><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>11098529</td><td>1105029</td></tr><tr><td>11098531</td><td>624163</td></tr><tr><td>11098531</td><td>1553691</td></tr><tr><td>11098531</td><td>1449555</td></tr><tr><td>11098531</td><td>1309633</td></tr><tr><td>11098531</td><td>1239060</td></tr><tr><td>11098531</td><td>1365569</td></tr><tr><td>11098531</td><td>1557766</td></tr><tr><td>11098531</td><td>1271998</td></tr><tr><td>11098531</td><td>1728212</td></tr><tr><td>11098531</td><td>396199</td></tr><tr><td>11098531</td><td>452188</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>12899761</td><td>764051</td></tr><tr><td>12899761</td><td>312733</td></tr><tr><td>12899761</td><td>612170</td></tr><tr><td>12899761</td><td>917164</td></tr><tr><td>12899761</td><td>787864</td></tr><tr><td>12899761</td><td>1142610</td></tr><tr><td>12899761</td><td>603364</td></tr><tr><td>12899763</td><td>1539032</td></tr><tr><td>12899763</td><td>750901</td></tr><tr><td>12899769</td><td>719585</td></tr><tr><td>12899771</td><td>1160655</td></tr><tr><td>12899775</td><td>1743151</td></tr></tbody></table></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Re-Ranking\n","metadata":{}},{"cell_type":"code","source":"# Generate Session Features \ndef generate_session_features(train_df_user):\n    df_session_grouped = train_df_user.sort('session', 'ts', descending=[False, True]).groupby('session')\n    df_session_grouped_clicks = train_df_user.filter(train_df_user['type'] == 0).sort('session', 'ts', descending=[False, True]).groupby('session')\n    df_session_grouped_carts = train_df_user.filter(train_df_user['type'] == 1).sort('session', 'ts', descending=[False, True]).groupby('session')\n    df_session_grouped_orders = train_df_user.filter(train_df_user['type'] == 2).sort('session', 'ts', descending=[False, True]).groupby('session')\n\n    # last event type and aid\n    last_event_type = df_session_grouped.agg(last_type=pl.col('type').first())\n\n    # length of session\n    session_length = df_session_grouped.agg(session_length=pl.col('ts').first() - pl.col('ts').last())\n\n    # duplication rate\n\n    # number of clicks, carts, orders, events that session\n    clicks_ratio = df_session_grouped_clicks.agg(clicks_ratio=pl.col('type').count())\n    carts_ratio = df_session_grouped_carts.agg(carts_ratio=pl.col('type').count())\n    orders_ratio = df_session_grouped_orders.agg(orders_ratio=pl.col('type').count())\n    events_ratio = df_session_grouped.agg(events_ratio=pl.col('type').count())\n\n    return [last_event_type, session_length, events_ratio, clicks_ratio, carts_ratio, orders_ratio]","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:22:34.630702Z","iopub.execute_input":"2023-08-02T06:22:34.631278Z","iopub.status.idle":"2023-08-02T06:22:34.646880Z","shell.execute_reply.started":"2023-08-02T06:22:34.631236Z","shell.execute_reply":"2023-08-02T06:22:34.645493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# AID FEATURES\ntrain_df_item = pl.concat([train, validA])\n\n# total interaction for aid\ninteraction_counts = train_df_item['aid'].value_counts().sort(by='counts').rename({\"counts\":\"interaction_count\"})\n\n# click for aid\nclick_counts = train_df_item.filter(train_df_item['type'] == 0).groupby('aid').agg(click_count=pl.count('type'))\n\n# cart for aid\ncart_counts = train_df_item.filter(train_df_item['type'] == 1).groupby('aid').agg(cart_count=pl.count('type'))\n\n# buy for aid\nbuy_counts = train_df_item.filter(train_df_item['type'] == 2).groupby('aid').agg(buy_count=pl.count('type'))\n\n# last ts for aid\nlast_ts = train_df_item.groupby('aid').agg(last_ts=pl.col('ts').max())\n\n# click, cart, buy ratios\nglobal_events_ratio = click_counts.join(cart_counts, on='aid').join(buy_counts, on='aid')\nglobal_events_ratio = global_events_ratio.with_columns(click2cart = pl.col('click_count') / pl.col('cart_count'))\nglobal_events_ratio = global_events_ratio.with_columns(cart2buy = pl.col('cart_count') / pl.col('buy_count'))\nglobal_events_ratio = global_events_ratio.with_columns(click2buy = pl.col('click_count') / pl.col('buy_count'))\nglobal_events_ratio = global_events_ratio.drop('click_count').drop('cart_count').drop('buy_count')\n\n# interaction rate in last 7 days\nlast_ts_int = train_df_item['ts'].max()\nlast_7_days_count = train_df_item.filter(train_df_item['ts'] >= last_ts_int - (7 * 24 * 60 * 60))['aid'].value_counts().sort(by='counts').rename({\"counts\":\"last7days_count\"})\nmerged = interaction_counts.join(last_7_days_count, on='aid')\nmerged = merged.with_columns(last7days_interaction_rate = pl.col('last7days_count') / pl.col('interaction_count'))\nlast7days_interaction_count = merged.drop('interaction_count').drop('last7days_count')\n\n# inclusion rate in all sessions\n# sessions_with_aid / total_sessions\ntotal_sessions = train_df_item['aid'].n_unique()\nunique_sessions = train_df_item.groupby('aid').agg(unique_sessions=pl.n_unique('session')).sort(by='unique_sessions')\ninclusion_rate = unique_sessions.with_columns(inclusion_rate = pl.col('unique_sessions') * 1000 / total_sessions).drop('unique_sessions')\n\n# average interactions per hour over all sessions\nnum_hours = train_df_item.groupby('aid').agg(num_hours = (pl.max('ts') - pl.min('ts')) / (60 * 60)).sort(by='num_hours')\nnum_hours = num_hours.with_columns(num_hours = pl.when(num_hours['num_hours']==0).then(1).otherwise(num_hours['num_hours']))\nmerged = num_hours.join(interaction_counts, on='aid')\naverage_interactions_ph = merged.with_columns(average_interactions_ph = pl.col('interaction_count') / pl.col('num_hours'))\naverage_interactions_ph = average_interactions_ph.drop('interaction_count').drop('num_hours')\n\n# average num clicks before buy\n# this bit too hard\nxd = train_df_item.sort(by=['session','ts'])\naid_features = [interaction_counts, click_counts, buy_counts, last_ts, global_events_ratio, last7days_interaction_count, inclusion_rate, average_interactions_ph]","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:22:34.649023Z","iopub.execute_input":"2023-08-02T06:22:34.649355Z","iopub.status.idle":"2023-08-02T06:23:41.582791Z","shell.execute_reply.started":"2023-08-02T06:22:34.649325Z","shell.execute_reply":"2023-08-02T06:23:41.581246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add candidates + features to df\n\n# # Using simple candidate generator\n# candidates_df = generate_candidates_simple(pl.concat([train, validA]))\n# train_df = validA.unique(subset=['session'])\n# train_df = candidates_df.join(train_df, on=\"session\", how=\"inner\").select(['session', 'aid'])\n\n# Using advanced candidate generator\ntrain_df = validA.to_pandas()\ntrain_df = train_df.sort_values(['session', 'ts'], ascending=[True, False]).groupby('session').apply(lambda x: generate_candidates(x, 0, covisit)).reset_index()\ntrain_df = pl.from_pandas(train_df)\ntrain_df.columns = ['session', 'aid']\ntrain_df = train_df.explode('aid')\n\nsession_features = generate_session_features(validA)\nfor session in session_features:\n    train_df = train_df.join(session, on='session', how='left')\n\nfor aid in aid_features:\n    train_df = train_df.join(aid, on='aid', how='left')","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:23:41.584434Z","iopub.execute_input":"2023-08-02T06:23:41.584839Z","iopub.status.idle":"2023-08-02T06:24:23.456496Z","shell.execute_reply.started":"2023-08-02T06:23:41.584805Z","shell.execute_reply":"2023-08-02T06:24:23.455480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add gts\ntype2id = {\"clicks\": 0, \"carts\": 1, \"orders\": 2}\nvalidB_long = validB.explode(\"ground_truth\").select([\n    pl.col(\"session\").cast(pl.datatypes.Int32),\n    pl.col(\"ground_truth\").cast(pl.datatypes.Int32).alias(\"aid\"),\n    pl.col(\"type\").map_dict(type2id).cast(pl.datatypes.Int8),\n]).with_columns(pl.lit(1).alias('gt'))\n\nvalidB_click = validB_long.filter(pl.col(\"type\") == 0)\nvalidB_cart = validB_long.filter(pl.col(\"type\") == 1)\nvalidB_order = validB_long.filter(pl.col(\"type\") == 2)\n\ntrain_df_click = train_df.join(validB_click, on=[\"session\", \"aid\"], how=\"left\").with_columns(pl.all().fill_null(0)).drop(\"type\")\ntrain_df_cart = train_df.join(validB_cart, on=[\"session\", \"aid\"], how=\"left\").with_columns(pl.all().fill_null(0)).drop(\"type\")\ntrain_df_order = train_df.join(validB_order, on=[\"session\", \"aid\"], how=\"left\").with_columns(pl.all().fill_null(0)).drop(\"type\")\n\nprint(train_df_click, train_df_cart, train_df_order)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:24:23.457660Z","iopub.execute_input":"2023-08-02T06:24:23.458034Z","iopub.status.idle":"2023-08-02T06:24:25.445064Z","shell.execute_reply.started":"2023-08-02T06:24:23.458002Z","shell.execute_reply":"2023-08-02T06:24:25.443833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Test Data","metadata":{}},{"cell_type":"code","source":"# Get test data\nimport numpy as np\nimport pandas as pd\n\nfrom pathlib import Path\n\ndata_path = Path('/kaggle/input/recsys-dataset/')\n\ntest_sessions = pd.DataFrame()\nchunks = pd.read_json(data_path / 'otto-recsys-test.jsonl', lines=True, chunksize=100_000)\n\nfor e, chunk in enumerate(chunks):\n    event_dict = {\n        'session': [],\n        'aid': [],\n        'ts': [],\n        'type': [],\n    }\n    if e < 2:\n        for session, events in zip(chunk['session'].tolist(), chunk['events'].tolist()):\n            for event in events:\n                event_dict['session'].append(session)\n                event_dict['aid'].append(event['aid'])\n                event_dict['ts'].append(event['ts'])\n                event_dict['type'].append(event['type'])\n        chunk_session = pd.DataFrame(event_dict)\n        test_sessions = pd.concat([test_sessions, chunk_session])\n    else:\n        break\n        \n\ntest_sessions = pl.from_pandas(test_sessions.reset_index(drop=True))\ntest_sessions = test_sessions.groupby('session').agg(pl.all()).sort(by='session')","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:24:25.446546Z","iopub.execute_input":"2023-08-02T06:24:25.446881Z","iopub.status.idle":"2023-08-02T06:24:41.685228Z","shell.execute_reply.started":"2023-08-02T06:24:25.446852Z","shell.execute_reply":"2023-08-02T06:24:41.683831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split test data into testA (session up to certain point) and testB (prediction)\ndictA = {'session': [], 'aid': [], 'ts': [], 'type': []}\ndictB = {'session': [], 'aid': [], 'ts': [], 'type': []}\n\nfor row in test_sessions.iter_rows():\n    split_idx = np.random.randint(1,len(row[1]))\n    dictA['session'].append(row[0])\n    dictA['aid'].append(row[1][:split_idx])\n    dictA['ts'].append(row[2][:split_idx])\n    dictA['type'].append(row[3][:split_idx])\n\n    dictB['session'].append(row[0])\n    dictB['aid'].append(row[1][split_idx:])\n    dictB['ts'].append(row[2][split_idx:])\n    dictB['type'].append(row[3][split_idx:])\n    \ntestA = pl.DataFrame(data=dictA).explode(['aid', 'ts', 'type'])\ntestB = pl.DataFrame(data=dictB)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:24:41.687049Z","iopub.execute_input":"2023-08-02T06:24:41.688560Z","iopub.status.idle":"2023-08-02T06:24:55.170465Z","shell.execute_reply.started":"2023-08-02T06:24:41.688522Z","shell.execute_reply":"2023-08-02T06:24:55.169320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate test candidates\ntest_df = generate_candidates_simple(testA).select([pl.all().cast(pl.datatypes.Int32)])    \nsession_features = generate_session_features(testA.select([\n    pl.col('session').cast(pl.datatypes.Int32),\n    pl.col('aid').cast(pl.datatypes.Int32),\n    pl.col('ts').apply(lambda x: x / 1000).cast(pl.datatypes.Int32),\n    pl.col(\"type\").map_dict(type2id).cast(pl.datatypes.Int8)\n]))\n\nfor session in session_features:\n    test_df = test_df.join(session, on='session', how='left')\n\nfor aid in aid_features:\n    test_df = test_df.join(aid, on='aid', how='left')\n    \ntest_df = test_df.with_columns(pl.all().fill_null(0))\nprint(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:24:55.171811Z","iopub.execute_input":"2023-08-02T06:24:55.172179Z","iopub.status.idle":"2023-08-02T06:24:57.931895Z","shell.execute_reply.started":"2023-08-02T06:24:55.172147Z","shell.execute_reply":"2023-08-02T06:24:57.931007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import GroupShuffleSplit\n\ntrain_click = train_df_click.to_pandas()\ntrain_cart = train_df_cart.to_pandas()\ntrain_order = train_df_order.to_pandas()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:24:57.937563Z","iopub.execute_input":"2023-08-02T06:24:57.937961Z","iopub.status.idle":"2023-08-02T06:24:58.551502Z","shell.execute_reply.started":"2023-08-02T06:24:57.937928Z","shell.execute_reply":"2023-08-02T06:24:58.550241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XG Boost with 5-fold CV\n# import xgboost as xgb\n# from sklearn.model_selection import GroupKFold\n\n# features = data.columns[: -1]\n\n# candidates = data\n# skf = GroupKFold(n_splits=5)\n# for fold,(train_idx, valid_idx) in enumerate(skf.split(candidates, candidates['gt'], groups=candidates['session'] )):\n\n#     X_train = candidates.loc[train_idx, features]\n#     y_train = candidates.loc[train_idx, 'gt']\n#     X_valid = candidates.loc[valid_idx, features]\n#     y_valid = candidates.loc[valid_idx, 'gt']\n\n#     groups_train = X_train.groupby('session').size().to_frame('size')['size'].to_numpy()\n#     groups_valid = X_valid.groupby('session').size().to_frame('size')['size'].to_numpy()\n#     dtrain = xgb.DMatrix(X_train, y_train, group=groups_train) \n#     dvalid = xgb.DMatrix(X_valid, y_valid, group=groups_valid) \n\n#     xgb_parms = {'objective':'rank:pairwise', 'tree_method':'hist'}\n#     model = xgb.train(xgb_parms, \n#         dtrain=dtrain,\n#         evals=[(dtrain,'train'),(dvalid,'valid')],\n#         num_boost_round=1000,\n#         verbose_eval=100)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:24:58.553018Z","iopub.execute_input":"2023-08-02T06:24:58.553359Z","iopub.status.idle":"2023-08-02T06:24:58.561530Z","shell.execute_reply.started":"2023-08-02T06:24:58.553329Z","shell.execute_reply":"2023-08-02T06:24:58.560213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pairwise Methods\nimport xgboost as xgb\nimport lightgbm\n\n# XGBoost\ndef train_XGB(data):\n    X_train = data.iloc[:,:-1]\n    y_train = data.iloc[:, -1]\n    \n    groups_train = X_train.groupby('session').size().to_frame('size')['size'].to_numpy()\n\n    model = xgb.XGBRanker(  \n        tree_method='hist',\n        booster='gbtree',\n        objective='rank:pairwise',\n        random_state=42, \n        learning_rate=0.1,\n        n_estimators=110\n    )\n\n    model.fit(\n        X_train, \n        y_train, \n        group=groups_train,\n        verbose=True\n    )\n    \n    return model\n\n# LightGBM\ndef train_LGBM(data):\n    X_train = data.iloc[:,:-1]\n    y_train = data.iloc[:, -1]\n    \n    groups_train = X_train.groupby('session').size().to_frame('size')['size'].to_numpy()\n    \n    model = lightgbm.LGBMRanker(\n        objective=\"lambdarank\",\n        boosting_type = \"gbdt\",\n        n_estimators = 5,\n        importance_type = \"gain\",\n        metric= \"ndcg\",\n        num_leaves = 10,\n        learning_rate = 0.05,\n        max_depth = -1\n    )\n    \n    model.fit(\n        X=X_train,\n        y=y_train,\n        group=groups_train\n    )\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:24:58.563355Z","iopub.execute_input":"2023-08-02T06:24:58.563675Z","iopub.status.idle":"2023-08-02T06:24:59.691854Z","shell.execute_reply.started":"2023-08-02T06:24:58.563647Z","shell.execute_reply":"2023-08-02T06:24:59.690511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model_name):\n    if model_name == 'XGB':\n        return [train_XGB(train_click), train_XGB(train_cart), train_XGB(train_order)]\n    elif model_name == 'LR':\n        return [train_LR(train_click), train_LR(train_cart), train_LR(train_order)]\n    elif model_name == 'LGBM':\n        return [train_LGBM(train_click), train_LGBM(train_cart), train_LGBM(train_order)]\n    else:\n        return None","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:24:59.702291Z","iopub.execute_input":"2023-08-02T06:24:59.703014Z","iopub.status.idle":"2023-08-02T06:24:59.716307Z","shell.execute_reply.started":"2023-08-02T06:24:59.702979Z","shell.execute_reply":"2023-08-02T06:24:59.715225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"actual_events = testB.explode(['aid', 'ts', 'type']).select([\n    pl.col('session').cast(pl.datatypes.Int32),\n    pl.col('aid').cast(pl.datatypes.Int32),\n    pl.col('ts').apply(lambda x: x / 1000).cast(pl.datatypes.Int32),\n    pl.col('type').map_dict(type2id).cast(pl.datatypes.Int8)\n]).to_pandas()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:24:59.717681Z","iopub.execute_input":"2023-08-02T06:24:59.718579Z","iopub.status.idle":"2023-08-02T06:25:00.216685Z","shell.execute_reply.started":"2023-08-02T06:24:59.718548Z","shell.execute_reply":"2023-08-02T06:25:00.215738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use Kaggle evaluation metric\ndef kaggle_evaluate(name, preds):\n    submission = preds\n    valid = actual_events\n    \n    submission['session'] = submission.session_type.apply(lambda x: int(x.split('_')[0]))\n    submission['type'] = submission.session_type.apply(lambda x: x.split('_')[1])\n    submission.labels = submission.labels.apply(lambda x: [int(i) for i in x.split(' ')][:20])\n\n    valid.type = valid.type.map(lambda idx: id2type[idx])\n    ground_truth = valid.groupby(['session', 'type'])['aid'].apply(list)\n    ground_truth = ground_truth.reset_index().rename(columns={'aid': 'labels'})\n    ground_truth.loc[ground_truth.type == 'clicks', 'labels'] = ground_truth.loc[ground_truth.type == 'clicks', 'labels'].str[:1]\n\n    submission_with_gt = submission.merge(ground_truth[['session', 'type', 'labels']], how='left', on=['session', 'type'])\n    submission_with_gt = submission_with_gt[~submission_with_gt.labels_y.isna()]\n    submission_with_gt['hits'] = submission_with_gt.apply(lambda df: len(set(df.labels_x).intersection(set(df.labels_y))), axis=1)\n    submission_with_gt['gt_count'] = submission_with_gt.labels_y.str.len().clip(0,20)\n\n    recall_per_type = submission_with_gt.groupby(['type'])['hits'].sum() / submission_with_gt.groupby(['type'])['gt_count'].sum() \n    local_validation_score = (recall_per_type * pd.Series({'clicks': 0.10, 'carts': 0.30, 'orders': 0.60})).sum()\n    print(f'{name}: {local_validation_score}')","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:25:00.218726Z","iopub.execute_input":"2023-08-02T06:25:00.219449Z","iopub.status.idle":"2023-08-02T06:25:00.231884Z","shell.execute_reply.started":"2023-08-02T06:25:00.219415Z","shell.execute_reply":"2023-08-02T06:25:00.230984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndef get_in_correct_format(pred_df):\n    click_preds = pred_df.groupby('session').agg(pl.col('aid').sort_by('click_scores', descending=True).slice(0,20))\n    cart_preds = pred_df.groupby('session').agg(pl.col('aid').sort_by('cart_scores', descending=True).slice(0,20))\n    order_preds = pred_df.groupby('session').agg(pl.col('aid').sort_by('order_scores', descending=True).slice(0,20))\n\n    click_new = click_preds.with_columns(\n        (pl.col('session').cast(pl.Utf8) + '_clicks').alias('session_type'), \n        pl.lit('clicks').alias('type'),\n        pl.col('aid').cast(pl.List(pl.Utf8))\n    ).rename({'aid':'labels'})\n    cart_new = cart_preds.with_columns(\n        (pl.col('session').cast(pl.Utf8) + '_carts').alias('session_type'), \n        pl.lit('carts').alias('type'),\n        pl.col('aid').cast(pl.List(pl.Utf8))\n    ).rename({'aid':'labels'})\n    order_new = order_preds.with_columns(\n        (pl.col('session').cast(pl.Utf8) + '_orders').alias('session_type'), \n        pl.lit('orders').alias('type'),\n        pl.col('aid').cast(pl.List(pl.Utf8))\n    ).rename({'aid':'labels'})\n\n    preds = pl.concat([click_new, cart_new, order_new]).to_pandas()\n    preds['labels'] = preds['labels'].apply(lambda x: ' '.join(x))\n    return preds","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:27:51.670242Z","iopub.execute_input":"2023-08-02T06:27:51.670929Z","iopub.status.idle":"2023-08-02T06:27:51.684372Z","shell.execute_reply.started":"2023-08-02T06:27:51.670894Z","shell.execute_reply":"2023-08-02T06:27:51.682894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(name, model):\n    model_click = model[0]\n    model_cart = model[1]\n    model_order = model[2]\n    \n    click_scores = model_click.predict(test_df.to_pandas())\n    cart_scores = model_cart.predict(test_df.to_pandas())\n    order_scores = model_order.predict(test_df.to_pandas())\n\n    pred_df = test_df.with_columns(click_scores = pl.lit(click_scores), cart_scores = pl.lit(cart_scores), order_scores = pl.lit(order_scores))\n    # print(pred_df)\n    \n    preds = get_in_correct_format(pred_df)\n    \n    kaggle_evaluate(name, preds)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:27:55.117133Z","iopub.execute_input":"2023-08-02T06:27:55.117586Z","iopub.status.idle":"2023-08-02T06:27:55.125050Z","shell.execute_reply.started":"2023-08-02T06:27:55.117551Z","shell.execute_reply":"2023-08-02T06:27:55.123814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Models and Evaluate","metadata":{}},{"cell_type":"code","source":"models = {'XGB' : train_model('XGB'), 'LGBM' : train_model('LGBM')}\n\nfor name, model in models:\n    evaluate_model(name, model)\n\n# model_click, model_cart, model_order = train_model('LR')","metadata":{"execution":{"iopub.status.busy":"2023-08-02T06:27:56.942871Z","iopub.execute_input":"2023-08-02T06:27:56.943705Z","iopub.status.idle":"2023-08-02T06:30:41.180158Z","shell.execute_reply.started":"2023-08-02T06:27:56.943670Z","shell.execute_reply":"2023-08-02T06:30:41.178509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}